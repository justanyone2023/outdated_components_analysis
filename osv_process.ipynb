{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff567ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9c9cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数来删除指定属性\n",
    "def remove_keys(json_data, keys_to_remove):\n",
    "    if isinstance(json_data, dict):\n",
    "        for key in keys_to_remove:\n",
    "            json_data.pop(key, None)\n",
    "        for key, value in json_data.items():\n",
    "            if isinstance(value, (dict, list)):\n",
    "                remove_keys(value, keys_to_remove)\n",
    "    elif isinstance(json_data, list):\n",
    "        for item in json_data:\n",
    "            remove_keys(item, keys_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a547c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON文件处理完成，并已保存到 processed_OSV/GHSA-c7m7-4257-h698.json\n"
     ]
    }
   ],
   "source": [
    "input_folder_path = 'npm_OSV'\n",
    "\n",
    "# 用于保存处理后的文件\n",
    "output_folder_path = 'processed_OSV'\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# 获取原始文件夹中所有JSON文件\n",
    "json_files = [f for f in os.listdir(input_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# 定义要删除的属性列表\n",
    "keys_to_remove = [\"references\", \"severity\", \"aliases\"]\n",
    "\n",
    "# 处理每个JSON文件\n",
    "for json_file in json_files:\n",
    "    # 构建完整的输入文件路径\n",
    "    input_file_path = os.path.join(input_folder_path, json_file)\n",
    "\n",
    "    # 读取JSON文件\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 删除属性\n",
    "    remove_keys(data, keys_to_remove)\n",
    "\n",
    "    # 构建完整的输出文件路径\n",
    "    output_file_path = os.path.join(output_folder_path, json_file)\n",
    "\n",
    "    # 保存处理后的JSON文件到新文件夹\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "print(\"JSON文件处理完成，并已保存到\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40f3b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据提取并已保存到 affected\n"
     ]
    }
   ],
   "source": [
    "# 创建文件夹，保存 \"affected\"和”id“\n",
    "output_folder_path = 'affected'\n",
    "\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "input_folder_path = 'processed_OSV'\n",
    "\n",
    "# 获取processed_OSV中所有JSON文件\n",
    "json_files = [f for f in os.listdir(input_folder_path) if f.endswith('.json')]\n",
    "\n",
    "for json_file in json_files:\n",
    "    \n",
    "    input_file_path = os.path.join(input_folder_path, json_file)\n",
    "\n",
    "    # 读取JSON文件\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 提取 \"affected\" 和 \"id\" 的值\n",
    "    affected_data = {\n",
    "        \"id\": data[\"id\"],\n",
    "        \"affected\": data[\"affected\"]\n",
    "    }\n",
    "\n",
    "    # 构建完整的输出文件路径\n",
    "    output_file_path = os.path.join(output_folder_path, json_file)\n",
    "\n",
    "    # 保存提取的数据到新文件夹\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(affected_data, file, indent=4)\n",
    "\n",
    "print(\"数据提取并已保存到\", output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba447bc",
   "metadata": {},
   "source": [
    "### 生成osv_affected表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53c4331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功写入到 'affected_data.csv' 文件\n"
     ]
    }
   ],
   "source": [
    "input_folder_path = 'affected'\n",
    "output_csv_path = 'affected_data.csv'\n",
    "json_files = [f for f in os.listdir(input_folder_path) if f.endswith('.json')]\n",
    "\n",
    "\n",
    "with open(output_csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "    # 指定逗号为分隔符\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',')\n",
    "\n",
    "    # 写入 CSV 文件的标题行\n",
    "    csv_writer.writerow([\"id\", \"package_name\", \"package_ecosystem\", \"package_purl\", \"ranges_type\", \"ranges_events_introduced\", \"ranges_events_fixed\", \"ranges_events_last_affected\", \"ranges_events_limit\", \"database_specific\"])\n",
    "\n",
    "    for json_file in json_files:\n",
    "        # 构建完整的输入文件路径\n",
    "        input_file_path = os.path.join(input_folder_path, json_file)\n",
    "\n",
    "        # 读取 JSON 文件\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # 提取 \"id\" 和 \"affected\" 数据\n",
    "        id_value = data[\"id\"]\n",
    "\n",
    "        affected_data = data[\"affected\"]\n",
    "\n",
    "        for affected_item in affected_data:\n",
    "            package_name = affected_item[\"package\"][\"name\"]\n",
    "            package_ecosystem = affected_item[\"package\"][\"ecosystem\"]\n",
    "            package_purl = affected_item[\"package\"][\"purl\"]\n",
    "\n",
    "            for each_range in affected_item[\"ranges\"]:\n",
    "                ranges_type = each_range[\"type\"]\n",
    "\n",
    "                eventsList = each_range.get(\"events\", [])\n",
    "\n",
    "                for event in eventsList:\n",
    "                    ranges_events_introduced = event.get(\"introduced\", None)\n",
    "                    ranges_events_fixed = event.get(\"fixed\", None)\n",
    "                    ranges_events_last_affected = event.get(\"last_affected\", None)\n",
    "                    ranges_events_limit = event.get(\"limit\", None)\n",
    "\n",
    "                # 处理 \"database_specific\" 的不同数据类型\n",
    "                if isinstance(affected_item[\"database_specific\"], str):\n",
    "                    database_specific = affected_item[\"database_specific\"]\n",
    "                elif isinstance(affected_item[\"database_specific\"], dict):\n",
    "                    # 从字典中提取键值对，并将它们拼接成一个字符串\n",
    "                    database_specific = \"; \".join([f\"{key}:{value}\" for key, value in affected_item[\"database_specific\"].items()])\n",
    "                else:\n",
    "                    database_specific = \"\"\n",
    "print(f\"数据已成功写入到 '{csv_file_path}' 文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374317d",
   "metadata": {},
   "source": [
    "### 生成osv_base表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd560ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功写入id_cweIds.csv、base_data.csv、id_aliases.csv、id_related.csv文件\n"
     ]
    }
   ],
   "source": [
    "input_folder_path = 'npm_OSV' # 完整数据\n",
    "\n",
    "json_files = [f for f in os.listdir(input_folder_path) if f.endswith('.json')]\n",
    "\n",
    "# 打开 CSV 文件以写入数据\n",
    "with open('id_cweIds.csv', 'w', newline='') as cwe_csvfile:\n",
    "    cwe_csv_writer = csv.writer(cwe_csvfile, delimiter=',')\n",
    "    # 写入 CSV 文件的标题行\n",
    "    cwe_csv_writer.writerow([\"id\", \"cwe_id\"])\n",
    "\n",
    "with open('base_data.csv', 'w', newline='') as base_csvfile:\n",
    "    base_csv_writer = csv.writer(base_csvfile, delimiter=',')\n",
    "    base_csv_writer.writerow([\"id\", \"summary\", \"details\", \"modified\", \"published\", \"severity\", \"schema_version\"])\n",
    "\n",
    "with open('id_aliases.csv', 'w', newline='') as aliases_csvfile:\n",
    "    aliases_csv_writer = csv.writer(aliases_csvfile, delimiter=',')\n",
    "    aliases_csv_writer.writerow([\"id\", \"alias_id\"])\n",
    "\n",
    "with open('id_related.csv', 'w', newline='') as related_csvfile:\n",
    "    related_csv_writer = csv.writer(related_csvfile, delimiter=',')\n",
    "    related_csv_writer.writerow([\"id\", \"related_id\"])\n",
    "    \n",
    "for json_file in json_files:\n",
    "    # 构建完整的输入文件路径\n",
    "    input_file_path = os.path.join(input_folder_path, json_file)\n",
    "\n",
    "    # 读取JSON文件\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    id_value = data.get(\"id\", None)\n",
    "    summary = data.get(\"summary\", None)\n",
    "    details = data.get(\"details\", None)\n",
    "    modified = data.get(\"modified\", None)\n",
    "    published = data.get(\"published\", None)\n",
    "    severity = None\n",
    "    aliases = data.get(\"aliases\", []) # 漏洞别名，数组\n",
    "    related = data.get(\"related\", []) # 密切相关的漏洞id，数组，好像为空\n",
    "    schema_version = data.get(\"schema_version\", None)\n",
    "    \n",
    "    # cwe_ids：两部分来源\n",
    "    # 1.affected[database_specific]里的[cwes][cweId](参考affected.csv)\n",
    "    # 2.database_specific[cwe_ids] (数组)\n",
    "    \n",
    "    \n",
    "    cwe_list = []\n",
    "    # 判断 \"database_specific\" 是否存在\n",
    "    if \"database_specific\" in data:\n",
    "        db_specific = data[\"database_specific\"]\n",
    "        severity = db_specific.get(\"severity\", None)\n",
    "\n",
    "        # 判断 \"cwe_ids\" 是否存在\n",
    "        if \"cwe_ids\" in db_specific:\n",
    "            cwe_ids = db_specific[\"cwe_ids\"]\n",
    "            cwe_list.extend(cwe_ids) # 把cwe_ids列表里的元素添加到cwe_list里\n",
    "            \n",
    "                        \n",
    "    # 检查 \"affected\" 是否存在\n",
    "    if \"affected\" in data:\n",
    "        affected_data = data[\"affected\"]\n",
    "\n",
    "        # 遍历 \"affected\" 数据\n",
    "        for affected_item in affected_data:\n",
    "            # 检查 \"database_specific\" 是否存在\n",
    "            if \"database_specific\" in affected_item:\n",
    "                database_specific = affected_item[\"database_specific\"]\n",
    "\n",
    "                # 检查 \"cwes\" 是否存在\n",
    "                if \"cwes\" in database_specific:\n",
    "                    cwes_data = database_specific[\"cwes\"]\n",
    "\n",
    "                    # 遍历 \"cwes\" 数组并提取每个 \"cweId\" 值\n",
    "                    for cwe in cwes_data:\n",
    "                        cwe_id = cwe[\"cweId\"]\n",
    "                        cwe_list.append(cwe_id)\n",
    "    \n",
    "    # 将cwe_list的值写到id_cweIds.csv中\n",
    "    with open('id_cweIds.csv', 'a', newline='') as cwe_csvfile:\n",
    "        cwe_csv_writer = csv.writer(cwe_csvfile, delimiter=',')\n",
    "        for each_cwe_id in cwe_list:\n",
    "            cwe_csv_writer.writerow([id_value, each_cwe_id])\n",
    "\n",
    "    # 将aliases list的值写到id_aliases.csv中\n",
    "    with open('id_aliases.csv', 'a', newline='') as aliases_csvfile:\n",
    "        aliases_csv_writer = csv.writer(aliases_csvfile, delimiter=',')\n",
    "        for each_alias in aliases:\n",
    "            aliases_csv_writer.writerow([id_value, each_alias])\n",
    "\n",
    "    # 将related list的值写到id_related.csv中\n",
    "    with open('id_related.csv', 'a', newline='') as related_csvfile:\n",
    "        related_csv_writer = csv.writer(related_csvfile, delimiter=',')\n",
    "        for each_related in related:\n",
    "            related_csv_writer.writerow([id_value, each_related])\n",
    "\n",
    "    # 将其他字段写到base_data.csv中\n",
    "    with open('base_data.csv', 'a', newline='') as base_csvfile:\n",
    "        base_csv_writer = csv.writer(base_csvfile, delimiter=',')\n",
    "        base_csv_writer.writerow([id_value, summary, details, modified, published, severity, schema_version])\n",
    "\n",
    "print(\"成功写入id_cweIds.csv、base_data.csv、id_aliases.csv、id_related.csv文件\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
