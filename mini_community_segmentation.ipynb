{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ec83ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T08:27:21.971949Z",
     "start_time": "2024-05-05T08:27:21.297309Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import igraph as ig\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import igraph as ig\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# 创建图对象，预先不指定方向，稍后定义\n",
    "G = ig.Graph(directed=True)\n",
    "\n",
    "vertices = set()\n",
    "edges = set()\n",
    "edges_to_add = []\n",
    "\n",
    "with open('data/mini_graph_supply_chain.csv', mode='r', newline='') as file:\n",
    "    dependents_data = csv.DictReader(file)\n",
    "    for row in dependents_data:\n",
    "        up_name = row['up_name']\n",
    "        down_name = row['down_name']\n",
    "\n",
    "        # 记录顶点和边\n",
    "        vertices.add(up_name)\n",
    "        vertices.add(down_name)\n",
    "        if (up_name, down_name) not in edges:\n",
    "            edges.add((up_name, down_name))\n",
    "            edges_to_add.append((up_name, down_name))\n",
    "\n",
    "# 一次性添加所有顶点和边\n",
    "G.add_vertices(list(vertices))\n",
    "G.add_edges(edges_to_add)\n",
    "print(f\"已添加 {len(edges_to_add)} 条初级依赖边。\")\n",
    "\n",
    "# 创建索引映射以加速查找\n",
    "name_to_index = {v['name']: v.index for v in G.vs}\n",
    "\n",
    "# 函数来处理每个边的二级依赖检查\n",
    "def check_second_level_dependencies(edge):\n",
    "    source = name_to_index[edge[0]]\n",
    "    target = name_to_index[edge[1]]\n",
    "    source_neighbors = set(G.neighbors(source, mode='out'))\n",
    "    target_neighbors = set(G.neighbors(target, mode='out'))\n",
    "\n",
    "    common_dependents = source_neighbors & target_neighbors\n",
    "    new_edges = []\n",
    "    for dep in common_dependents:\n",
    "        if (source, dep) not in edges:\n",
    "            print(f'append {source}, {dep}')\n",
    "            new_edges.append((source, dep))\n",
    "    return new_edges\n",
    "\n",
    "# 使用 ThreadPoolExecutor 处理二级依赖\n",
    "new_edges_to_add = []\n",
    "print(f\"Total edges to process: {len(edges_to_add)}\")\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = {executor.submit(check_second_level_dependencies, edge): edge for edge in edges_to_add}\n",
    "    for i, future in enumerate(as_completed(futures), 1):\n",
    "        new_edges = future.result()\n",
    "        new_edges_to_add.extend(new_edges)\n",
    "        print(f\"处理进度：{i}/{len(edges_to_add)} (完成了 {(i/len(edges_to_add) * 100):.2f}%)\")\n",
    "\n",
    "# 主线程中添加所有新边\n",
    "for edge in new_edges_to_add:\n",
    "    G.add_edge(edge[0], edge[1])\n",
    "    edges.add((edge[0], edge[1]))\n",
    "\n",
    "print(f\"完成二级依赖边添加，共 {len(new_edges_to_add)} 条。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd71d70",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-05T08:27:10.853317Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看图的一些属性\n",
    "print(f\"顶点数: {G.vcount()}\")\n",
    "print(f\"边数: {G.ecount()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个字典以存储节点属性\n",
    "node_attributes = {}\n",
    "\n",
    "# 从文件中读取节点属性数据\n",
    "with open('new_outdate_osv_cwe_ids.csv', mode='r', newline='') as file:\n",
    "    cwe_data = csv.DictReader(file)\n",
    "    for row in cwe_data:\n",
    "        package_name = row['name']\n",
    "        cwe_id = row['cwe_id']\n",
    "\n",
    "        # 检查顶点是否存在（某些包发生了漏洞事件但没有dependent包，所以不在图中）\n",
    "        try:\n",
    "            node = G.vs.find(name=package_name)\n",
    "        except ValueError:\n",
    "            # 如果顶点不存在，跳过\n",
    "            print(f\" {package_name} does not exist in G\")\n",
    "            continue\n",
    "        if node:\n",
    "            node['cwe_ids'].append(cwe_id)\n",
    "\n",
    "for node, attributes in node_attributes.items():\n",
    "    node_index = G.vs.find(name=node).index  # 获取节点的索引\n",
    "    if 'package_name' in attributes:\n",
    "        G.vs[node_index]['attributes'] = attributes\n",
    "    else:\n",
    "        print(f\"Warning: Node '{node}' does not have 'package_name' attribute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3367cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 保存图 G 到文件\n",
    "with open('graph.pkl', 'wb') as file:\n",
    "    pickle.dump(G, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Louvain 算法进行社区检测，并传入分辨率参数\n",
    "undirected_G = G.as_undirected()\n",
    "best_partition = undirected_G.community_multilevel(resolution=0.2) # 分辨率越大，社区数量越多\n",
    "com_num = len(best_partition)\n",
    "print(f\"共划分为{com_num}个社区\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3493b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 输出每个社区的个数\n",
    "for community_index, community in enumerate(best_partition):\n",
    "    print(f\"Community {community_index + 1}:\")\n",
    "    print(f\"数量：{len(community)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac9aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, community in enumerate(best_partition):\n",
    "    community_nodes[i] = list(community)\n",
    "\n",
    "# 将社区数据保存到 CSV 文件\n",
    "with open('communities.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Community_ID', 'Node'])\n",
    "    for community_id, nodes in community_nodes.items():\n",
    "        for node in nodes:\n",
    "            writer.writerow([community_id, node])\n",
    "\n",
    "print(\"社区数据已保存到 'communities.csv' 文件中。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "graph",
   "language": "python",
   "display_name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
